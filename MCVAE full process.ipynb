{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.models import define_VAE, define_MM\n",
    "from keras.utils import plot_model\n",
    "import h5py\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data_prep import VAEdataPrep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps=16\n",
    "features=131\n",
    "latent_units= 30\n",
    "\n",
    "enc_units = 70\n",
    "dec_units = 70\n",
    "dropout = 0.1\n",
    "beta = 2\n",
    "learning_rate = 0.001\n",
    "epsilon_std = 1.\n",
    "\n",
    "mdn_seq_len = 10\n",
    "mdn_hidden_units = 50\n",
    "number_mixtures = 10\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_full, _, _ = define_VAE(enc_units=enc_units,\n",
    "                dec_units=dec_units,\n",
    "                latent_units=latent_units,\n",
    "                timesteps=timesteps,\n",
    "                features=features,\n",
    "                dropout=dropout,\n",
    "                beta=beta,\n",
    "                learning_rate=learning_rate,\n",
    "                epsilon_std=epsilon_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data (includes generator setup)\n",
    "The data must be converted from arrays of integers to sliced, one hot encoded vectors.  \n",
    "The encoded vectors are sliced according to the given 'timesteps' for one sequence.  \n",
    "  \n",
    "After being sliced, the vectors, hereby called 'bars', are saved as numpy arrays in directories with names that the user defines. Old directories with the same name will be deleted when calling the function. The user can check the progress with the option 'print_progress'.  \n",
    "'print_progress' can be a number for selecting how many times to print the progress, or it can be True / False to print all or nothing of the progress.  \n",
    "  \n",
    "Both functions skips songs that are above the average bar number of [113 bars](https://www.statcrunch.com/5.0/viewreport.php?groupid=948&reportid=28647), and songs below or equal to 1 bar. \n",
    "  \n",
    "### Define names for encoder and decoder input directories + fit_generator setup file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_dir = \"enc_in\"\n",
    "decoder_dir = \"dec_in\"\n",
    "encoder_dir_songs = \"song_enc_in\"\n",
    "\n",
    "generator_IDs_file = \"generator_IDs.npy\" # must be .npy. Will be saved in datasets/id_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set correct dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = \"datasets/test_dataset.npy\"\n",
    "vae_data_prep = VAEdataPrep(timesteps=timesteps, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_data_prep.create_bars_dir(encoder_directory=encoder_dir,\n",
    "                        decoder_directory=decoder_dir,\n",
    "                        dataset_file=dataset_file,\n",
    "                        generator_IDs_file=generator_IDs_file,\n",
    "                        print_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_data_prep.create_songs_dir(encoder_directory=encoder_dir_songs,\n",
    "                        dataset_file=dataset_file,\n",
    "                        print_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup GPU (voluntary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "# Only for GPU use:\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.generators import VAEDataGenerator\n",
    "\n",
    "# Parameters\n",
    "params = {'dim': (timesteps, features),\n",
    "          'enc_dir' : encoder_dir,\n",
    "          'dec_dir' : decoder_dir,\n",
    "          'batch_size': batch_size,\n",
    "          'shuffle': True}\n",
    "\n",
    "ID_list_dict = {}\n",
    "\n",
    "# Datasets\n",
    "ID_list = np.load(\"datasets/id_lists/\" + generator_IDs_file)\n",
    "ID_list_dict[\"train\"] = ID_list.item().get(\"train\")\n",
    "ID_list_dict[\"validation\"] = ID_list.item().get(\"validation\")\n",
    "\n",
    "# Generators\n",
    "training_generator = VAEDataGenerator(ID_list_dict['train'], **params)\n",
    "validation_generator = VAEDataGenerator(ID_list_dict['validation'], **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,TensorBoard\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "tb_dir = \"tb\"\n",
    "filepath=\"weights/test_run-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=tb_dir, batch_size=batch_size)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "num_training_samples = 10000\n",
    "num_validation_samples = 1500\n",
    "steps_per_epoch = num_training_samples // batch_size\n",
    "validation_steps = num_validation_samples // batch_size\n",
    "\n",
    "\n",
    "# Train model on dataset\n",
    "vae_full.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps,\n",
    "                    use_multiprocessing=False,\n",
    "                    epochs=epochs,\n",
    "                    verbose=2,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create mixture model inputs\n",
    "\n",
    "Initialize VAE encoder, and set the path for the best weights from the previous training. The encoder weights from this set of weights will be set to the encoder.  \n",
    "  \n",
    "To create mixture model inputs, all songs from directory of songs (created earlier) will be processed by the encoder, producing a latent vector (z) for each bar. All songs saved as sequences of z's.   \n",
    "\n",
    "<img src=\"imgs/project_info/full_model.png\" width="400">",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"imgs/project_info/z_creation.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set path for the best VAE weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_weights_path = \"weights/\" + \"test_run-99-0.80.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE encoder\n",
    "_, vae_enc, _ = define_VAE(enc_units=enc_units,\n",
    "                dec_units=dec_units,\n",
    "                latent_units=latent_units,\n",
    "                timesteps=timesteps,\n",
    "                features=features,\n",
    "                dropout=dropout,\n",
    "                beta=beta,\n",
    "                learning_rate=learning_rate,\n",
    "                epsilon_std=epsilon_std)\n",
    "\n",
    "vae_full.load_weights(vae_weights_path)\n",
    "print(\"Loaded VAE weights from disk\")\n",
    "\n",
    "# get all weights\n",
    "all_weights = vae_full.get_weights()\n",
    "\n",
    "# find encoder weights position\n",
    "decoder_position = len(vae_enc.get_weights())\n",
    "encoder_weights = all_weights[:decoder_position]\n",
    "\n",
    "# set encoder weights\n",
    "vae_enc.set_weights(encoder_weights)\n",
    "print(\"Set VAE weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define name for z-dataset file\n",
    "\n",
    "Prefereably put the z-dataset file in the folder *datasets*.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dataset_file = \"datasets/z_dataset.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining a name for the file, run the 'create_mm_data' from the MDNdataPrep module.  \n",
    "  \n",
    "The function show a progress bar, which usually gets a SynchronisationWarning, this doesn't cause a problem for the z-creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data_prep import MDNdataPrep\n",
    "\n",
    "mdn_data_prep = MDNdataPrep(timesteps=timesteps,\n",
    "                            features=features,\n",
    "                            z_dim=latent_units,\n",
    "                            z_dataset_file=z_dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdn_data_prep.create_mm_data(vae_enc=vae_enc, encoder_dir_songs=encoder_dir_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define name for sliced z-dataset file, generator-IDs file and MDN sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_z_dataset_file = \"datasets/sliced_z_dataset.h5\"\n",
    "MDNgenerator_IDs_file = \"datasets/mdn_generator_IDs.npy\" #must be numpy\n",
    "mdn_seq_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdn_data_prep.slice_z_data_for_mdn(sliced_z_dataset_file, MDNgenerator_IDs_file, mdn_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "hf_mdn = h5py.File(sliced_z_dataset_file, 'r')\n",
    "\n",
    "print(\"Number of sliced z's: \", len(list(hf_mdn.keys()))/2)\n",
    "print(\"Is the first time step of y the same as the second time step of x? \\n\" ,\\\n",
    "      list(hf_mdn.get(\"z_x_id-1\"))[1] == list(hf_mdn.get(\"z_y_id-1\"))[0])\n",
    "\n",
    "hf_mdn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define MDN hidden units and number of mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdn_hidden_units = 50\n",
    "number_mixtures = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initalize one MDN to train and one for decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_full, mm_decoder = define_MM(seq_len=mdn_seq_len,\n",
    "                                vae_latent_units=latent_units,\n",
    "                                hidden_units=mdn_hidden_units,\n",
    "                                number_mixtures=number_mixtures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup the MDN generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.generators import MDNDataGenerator\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "params = {'dim': (mdn_seq_len, latent_units),\n",
    "          'batch_size': batch_size,\n",
    "          'dataset_path': sliced_z_dataset_file,\n",
    "          'shuffle': True}\n",
    "\n",
    "ID_list_dict = {}\n",
    "ID_list = np.load(MDNgenerator_IDs_file)\n",
    "\n",
    "ID_list_dict[\"train\"] = ID_list.item().get(\"train\")\n",
    "ID_list_dict[\"validation\"] = ID_list.item().get(\"validation\")\n",
    "\n",
    "# Generators\n",
    "training_generator = MDNDataGenerator(ID_list_dict['train'], **params)\n",
    "validation_generator = MDNDataGenerator(ID_list_dict['validation'], **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train MDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "tb_log_dir = \"tb/mdn\"\n",
    "\n",
    "num_training_samples = 10000\n",
    "num_validation_samples = 1000\n",
    "steps_per_epoch = int(num_training_samples / batch_size)\n",
    "validation_steps = int(num_validation_samples / batch_size)\n",
    "\n",
    "# Train model on dataset\n",
    "filepath=\"weights/mdn_test_run-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir=tb_log_dir, batch_size=batch_size)\n",
    "\n",
    "history = mm_full.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps,\n",
    "                    use_multiprocessing=False,\n",
    "                    epochs=epochs,verbose=2,callbacks=[keras.callbacks.TerminateOnNaN(),\n",
    "                                                       checkpoint,\n",
    "                                                       tensorboard])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
