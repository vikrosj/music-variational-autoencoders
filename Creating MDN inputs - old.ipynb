{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import model_from_json\n",
    "from data_prep import one_hot_decode, get_bars_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "timesteps = 16\n",
    "cardinality = 131\n",
    "latent_dim = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some details\n",
    "\n",
    "The MDN will predict sequences of bars, and the sequences must be equal. Therefore, some preparation must be done. Some songs in the dataset are long and some songs are short, this calls for some decisions to be made.  \n",
    "  \n",
    "Here's the solution:  \n",
    "An [average song length](url=https://www.statcrunch.com/5.0/viewreport.php?groupid=948&reportid=28647) is 226 seconds.  \n",
    "  \n",
    "The [average bpm](url=https://learningmusic.ableton.com/make-beats/tempo-and-genre.html) for a song is 120. \n",
    "\n",
    "The [semiquaver length](url=http://bradthemad.org/guitar/tempo_explanation.php) is 15 / bpm.  \n",
    "  \n",
    "15 / 120 = 0.125 seconds per semiquaver  \n",
    "0.125 * 16 notes per vector = 2 seconds per bar   \n",
    "226 / 2 = 113 bars per song.  \n",
    "  \n",
    "### So!\n",
    "\n",
    "something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, dirs, files in os.walk(\"songs_encoder_inputs\"):\n",
    "    for file in files:\n",
    "        song_len = len(np.load(path + os.sep + file))\n",
    "        \n",
    "        # Removing songs shorter than one bar\n",
    "        if song_len == 0: \n",
    "            os.remove(path + os.sep + file)\n",
    "            print(\"Removing empty list.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making sure no huge songs are occupying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_lengths = []\n",
    "for path, dirs, files in os.walk(\"songs_encoder_inputs\"):\n",
    "    for file in files:\n",
    "        song_lengths.append(len(np.load(path + os.sep + file)))\n",
    "        \n",
    "sort_songlist = sorted(song_lengths)\n",
    "print(\"Lenght of list before checking song lengths: \", len(sort_songlist))\n",
    "\n",
    "new_list = []    \n",
    "\n",
    "for i in range(len(sort_songlist)):\n",
    "    if sort_songlist[i] < 1000:\n",
    "        new_list.append(sort_songlist[i])\n",
    "    else:\n",
    "        print(\"Song too long. {} bars. Removing.\".format(sort_songlist[i]))\n",
    "        \n",
    "print(\"Lenght of list after checking song lengths: \", len(sort_songlist))\n",
    "print(\"Remaining number of bars in dataset: \", sum(new_list))\n",
    "plt.hist(new_list,bins=100) \n",
    "plt.title(\"Histogram of bar lengths.\")\n",
    "plt.ylabel(\"No. of items\")\n",
    "plt.xlabel(\"Bar length\")\n",
    "plt.xlim(min(new_list),max(new_list))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('encoder_512_64.json', 'r')\n",
    "loaded_infenc = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "infenc = model_from_json(loaded_infenc)\n",
    "\n",
    "# load weights into new model\n",
    "infenc.load_weights(\"encoder_512_64.h5\")\n",
    "print(\"Loaded infenc model and weights from disk\")\n",
    "\n",
    "\n",
    "json_file = open('decoder_512_64.json', 'r')\n",
    "loaded_infdec = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "infdec = model_from_json(loaded_infdec)\n",
    "\n",
    "# load weights into new model\n",
    "infdec.load_weights(\"decoder_512_64.h5\")\n",
    "print(\"Loaded infdec model and weights from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get no of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path, dirs, files = next(os.walk(\"songs_encoder_inputs\"))\n",
    "file_count = len(files)\n",
    "\n",
    "file_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one song file\n",
    "f = np.load(\"songs_encoder_inputs/id-0.npy\")\n",
    "\n",
    "print(\"Shape of first song file: \", f.shape)\n",
    "print(\"No. of slices: \", f.shape[0])\n",
    "print(\"Timesteps: \", f.shape[1])\n",
    "print(\"One encoded note: \", f[0][0])\n",
    "print(\"One decoded bar :\", one_hot_decode(f[31]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to get z-list from song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate target given source sequence\n",
    "def create_z_list(infenc, song, latent_dim):\n",
    "    z_list = []\n",
    "    \n",
    "    for bar in song:\n",
    "        \n",
    "        bar = bar.reshape(1, timesteps, cardinality)\n",
    "        \n",
    "        # encode\n",
    "        encoder_output = infenc.predict(bar)\n",
    "\n",
    "        z = encoder_output[2]\n",
    "        z = z.reshape(1, 1, latent_dim)\n",
    "        z_list.append(z)\n",
    "    \n",
    "    return z_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('z_dataset.h5', 'w')\n",
    "\n",
    "for i in tqdm(range(file_count)):\n",
    "    \n",
    "    song_from_file = np.load(\"songs_encoder_inputs/id-\" + str(i) + \".npy\")\n",
    "    song_len = song_from_file.shape[0]\n",
    "    \n",
    "    # reshaping to work as input to lstm\n",
    "    song = np.array(song_from_file).reshape(song_len, timesteps, cardinality)\n",
    "    \n",
    "    # predicting list of z's\n",
    "    z_list = create_z_list(infenc, song, latent_dim)\n",
    "    \n",
    "    # appending list of z's to dataset\n",
    "    h5f.create_dataset('z_list_'+str(counter), data= np.array(z_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
