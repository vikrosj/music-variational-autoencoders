{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from data_prep import one_hot_decode, get_bars_dataset, one_hot_encode, one_hot_decode_song\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from predictions import define_models,mdn_predict_sequence\n",
    "from music21 import converter, instrument, note, chord, stream, midi, environment\n",
    "%matplotlib inline\n",
    "import os\n",
    "from midi_handling import noteArrayToStream, switch_range\n",
    "from music21 import *\n",
    "import numpy as np\n",
    "mdn_dataset_path = \"h5_files/mdn_dataset_b1.h5\"\n",
    "vae_weights_path = \"weights/512_64/weights-improvement-2455-1.00.hdf5\"\n",
    "import h5py\n",
    "from numba import jit\n",
    "from tqdm import tqdm\n",
    "from context import * # imports the MDN layer\n",
    "import keras\n",
    "from ngram_compute import int_list_to_str, compute_ngram_prob\n",
    "############################ MDN initalisation ###################################\n",
    "SEQ_LEN = 16\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_UNITS = 512\n",
    "EPOCHS = 400\n",
    "SEED = 2345  # set random seed for reproducibility\n",
    "\n",
    "\n",
    "OUTPUT_DIMENSION = 64\n",
    "NUMBER_MIXTURES = 10\n",
    "\n",
    "\n",
    "np.random.seed(SEED)\n",
    "############################ VAE initalisation ###################################\n",
    "n_features = 131\n",
    "timesteps = 16\n",
    "learning_rate = 0.0001\n",
    "n_encoder_units = 512\n",
    "n_decoder_units = n_encoder_units\n",
    "latent_dim = 64\n",
    "dropout=0.3\n",
    "beta=1\n",
    "############################ MUSESCORE intialisation ###############################\n",
    "environment.set(\"musescoreDirectPNGPath\", \"/usr/bin/musescore\")\n",
    "\n",
    "############################ NGRAM intialisation ###############################\n",
    "tqdm.monitor_interval = 0\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize empty dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['a', 'c0', 'c1', 'c2', 'c3', 'c4', 'b']\n",
    "\n",
    "df_idx = 0\n",
    "df1 = pd.DataFrame(columns=cols, index=[df_idx])\n",
    "\n",
    "for i in range(1):\n",
    "    df1.loc[i].a = np.nan\n",
    "    df1.loc[i].c0 = np.nan\n",
    "    df1.loc[i].c1 = np.nan\n",
    "    df1.loc[i].c2 = np.nan\n",
    "    df1.loc[i].c3 = np.nan\n",
    "    df1.loc[i].c4 = np.nan\n",
    "    df1.loc[i].b = np.nan\n",
    "    \n",
    "with open('ngram_results_true.csv', 'w') as f:\n",
    "    df1.to_csv(f, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict intermediate songs and compute likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum likelihood for a sequence (with Laplace smoothing) is:\n",
    "\n",
    "```python\n",
    "MLE = (Count(n grams) + 1)/ (Count(n-1 grams) + V)\n",
    "```\n",
    "\n",
    "V is the number of unique tokens in the vocabulary, in this case: \n",
    "\n",
    "```python\n",
    "V = 130\n",
    "```\n",
    "\n",
    "The absolute worst MLE for a sequence is -759.3353742710694:\n",
    "\n",
    "```python\n",
    "for i in range(16 * 10 - 4):\n",
    "    prob += log(float(0 + 1 / 0 + 130))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 5\n",
    "\n",
    "z_dataset = h5py.File(\"h5_files/z_dataset.h5\", \"r\")\n",
    "\n",
    "with h5py.File(\"h5_files/As_and_Bs.h5\", \"r\") as A_and_B:\n",
    "    \n",
    "    for item in tqdm(list(A_and_B.keys())):      \n",
    "\n",
    "        # update index for dataframe\n",
    "        df_idx += 1\n",
    "        \n",
    "        cols = ['a', 'c0', 'c1', 'c2', 'c3', 'c4', 'b']\n",
    "\n",
    "        # create temporary dataframe\n",
    "        df2 = pd.DataFrame(columns=cols, index=[df_idx])\n",
    "\n",
    "        \n",
    "        ################ song A ###################################\n",
    "        \n",
    "        # get song A compute ngram MLE\n",
    "        songA = np.array(A_and_B.get(item))[0:length]\n",
    "        A = one_hot_decode_song(songA)\n",
    "        \n",
    "        # add to dataframe position a\n",
    "        df2.loc[df_idx].a = compute_ngram_prob(A)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ################ song B ###################################\n",
    "        # get B position\n",
    "        endpos = int(item.split(\"_\")[0][1:]) + 1\n",
    "        B_pos = \"B\" + item.split(\"_\")[0][1:] + \"_z\" +  str( endpos )\n",
    "    \n",
    "        songB = np.array(A_and_B.get(B_pos))[0:length]\n",
    "        # get song B compute ngram MLE\n",
    "        B = one_hot_decode_song(songB)\n",
    "        \n",
    "        # add to dataframe position b\n",
    "        df2.loc[df_idx].b = compute_ngram_prob(B)\n",
    "        \n",
    "\n",
    "        ################## interpolating ###########################\n",
    "        alpha = 0.1 \n",
    "        \n",
    "        # update alpha 5 times (0.1 - 0.9)\n",
    "        for i in range(5):\n",
    "            pred_song = []   \n",
    "            \n",
    "\n",
    "            # mdn loop through 5 timesteps of a song\n",
    "            for j in range(length):\n",
    "\n",
    "                # initalize first z, mdn takes it from here\n",
    "                song = alpha*songA[j] + float(1-alpha)*songB[j]\n",
    "\n",
    "                pred_song.append(one_hot_decode(song.reshape(SEQ_LEN, n_features)))\n",
    "\n",
    "            # compute ngram probability of song and add to dataframe row\n",
    "            c_pos = \"c\" + str(i)\n",
    "\n",
    "            df2.loc[[df_idx],[c_pos]] = compute_ngram_prob(np.ravel(np.array(pred_song)))\n",
    "            \n",
    "            # update alpha\n",
    "            alpha += 0.2\n",
    "            \n",
    "        # append dataframe\n",
    "        with open('ngram_results_true.csv', 'a') as f:\n",
    "            df2.to_csv(f, header=False)\n",
    "\n",
    "\n",
    "z_dataset.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
