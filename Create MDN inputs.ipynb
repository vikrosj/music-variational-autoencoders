{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "from data_prep import one_hot_decode\n",
    "from predictions import define_models\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "timesteps = 16\n",
    "cardinality = 131\n",
    "latent_dim = 64\n",
    "avg_song_len = 113\n",
    "\n",
    "\n",
    "vae_weights_path = \"weights/512_64/weights-improvement-2455-1.00.hdf5\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "############################ VAE initalisation ###################################\n",
    "n_features = 131\n",
    "timesteps = 16\n",
    "learning_rate = 0.0001\n",
    "n_encoder_units = 512\n",
    "n_decoder_units = n_encoder_units\n",
    "latent_dim = 64\n",
    "dropout=0.3\n",
    "beta=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97, 16, 131), 97)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = np.load('songs_encoder_inputs/id-7688.npy')\n",
    "f.shape, len(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some details\n",
    "\n",
    "The MDN will predict sequences of bars, and the sequences must be equal. Therefore, some preparation must be done. Some songs in the dataset are long and some songs are short, this calls for some decisions to be made.  \n",
    "  \n",
    "Here's the solution:  \n",
    "An [average song length](url=https://www.statcrunch.com/5.0/viewreport.php?groupid=948&reportid=28647) is 226 seconds.  \n",
    "  \n",
    "The [average bpm](url=https://learningmusic.ableton.com/make-beats/tempo-and-genre.html) for a song is 120. \n",
    "\n",
    "The [semiquaver length](url=http://bradthemad.org/guitar/tempo_explanation.php) is 15 / bpm.  \n",
    "  \n",
    "15 / 120 = 0.125 seconds per semiquaver  \n",
    "0.125 * 16 notes per vector = 2 seconds per bar   \n",
    "226 / 2 = 113 bars per song.  \n",
    " \n",
    "  \n",
    "#### But first, let's remove empty lists and too long songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"post_process3 = []\n",
    "pre_process = []\n",
    "\n",
    "for path, dirs, files in os.walk(\"songs_encoder_inputs\"):\n",
    "    for file in files:\n",
    "        song_len = len(np.load(path + os.sep + file))\n",
    "        \n",
    "        # Removing songs shorter than one bar\n",
    "        if song_len == 0:\n",
    "            pre_process.append(len(np.load(path + os.sep + file)))\n",
    "            os.remove(path + os.sep + file)\n",
    "            print(\"Removing empty list.\")\n",
    "            \n",
    "        elif song_len > 3 * avg_song_len:\n",
    "            pre_process.append(len(np.load(path + os.sep + file)))\n",
    "            os.remove(path + os.sep + file)\n",
    "            print(\"Song too long. {} bars. Removing.\".format(song_len))\n",
    "            \n",
    "        else: \n",
    "            post_process3.append(song_len)\n",
    "            pre_process.append(len(np.load(path + os.sep + file)))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, dirs, files in os.walk(\"songs_encoder_inputs\"):\n",
    "    for file in files:\n",
    "        song_len = len(np.load(path + os.sep + file))\n",
    "        if song_len > 80000:\n",
    "            print(song_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded VAE weights from disk\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "train, infenc, _ = define_models(n_encoder_units=n_encoder_units,\n",
    "                                        n_decoder_units=n_decoder_units,\n",
    "                                        latent_dim=latent_dim, \n",
    "                                      timesteps=timesteps,\n",
    "                                      n_features=n_features,\n",
    "                                      learning_rate=learning_rate,\n",
    "                                        dropout=dropout,\n",
    "                                      beta=beta,\n",
    "                                        epsilon_std=1.)\n",
    "\n",
    "train.load_weights(vae_weights_path)\n",
    "print(\"Loaded VAE weights from disk\")\n",
    "\n",
    "all_weights = train.get_weights()\n",
    "decoder_position = len(infenc.get_weights())\n",
    "encoder_weights = all_weights[:decoder_position]\n",
    "\n",
    "infenc.set_weights(encoder_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get no of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9977"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path, dirs, files = next(os.walk(\"songs_encoder_inputs\"))\n",
    "file_count = len(files)\n",
    "\n",
    "file_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of first song file:  (72, 16, 131)\n",
      "No. of slices:  72\n",
      "Timesteps:  16\n",
      "One encoded note:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "One decoded bar : [67, 129, 129, 129, 66, 129, 66, 129, 66, 129, 64, 129, 64, 129, 66, 129]\n"
     ]
    }
   ],
   "source": [
    "# one song file\n",
    "f = np.load(\"songs_encoder_inputs/id-0.npy\")\n",
    "\n",
    "print(\"Shape of first song file: \", f.shape)\n",
    "print(\"No. of slices: \", f.shape[0])\n",
    "print(\"Timesteps: \", f.shape[1])\n",
    "print(\"One encoded note: \", f[0][0])\n",
    "print(\"One decoded bar :\", one_hot_decode(f[31]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to get z-list from song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate target given source sequence\n",
    "def create_z_array(infenc, song, latent_dim):\n",
    "    z_list = []\n",
    "    \n",
    "    for bar in song:\n",
    "        \n",
    "        bar = bar.reshape(1, timesteps, cardinality)\n",
    "        \n",
    "        # encode\n",
    "        encoder_output = infenc.predict(bar)\n",
    "\n",
    "        z = encoder_output[2]\n",
    "        z = z.reshape(1, 1, latent_dim)\n",
    "        z_list.append(z)\n",
    "    \n",
    "    return np.array(z_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the z-dataset\n",
    "\n",
    "(This takes time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/9977 [00:07<4:20:53,  1.57s/it]/usr/local/lib/python3.5/dist-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "100%|██████████| 9977/9977 [4:22:32<00:00,  1.58s/it]  \n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('z_dataset_pre.h5', 'w')\n",
    "\n",
    "for i in tqdm(range(file_count)):\n",
    "    \n",
    "    song_from_file = np.load(\"songs_encoder_inputs/id-\" + str(i) + \".npy\")\n",
    "    song_len = song_from_file.shape[0]\n",
    "    \n",
    "    # reshaping to work as input to lstm\n",
    "    song = np.array(song_from_file).reshape(song_len, timesteps, cardinality)\n",
    "    \n",
    "    # predicting list of z's\n",
    "    z_array = create_z_array(infenc, song, latent_dim)\n",
    "    \n",
    "    # appending list of z's to dataset\n",
    "    h5f.create_dataset(\"z_list\" + str(i), data=z_array)\n",
    "    \n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice the z's into the required sequence lenght for the MDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 16\n",
    "\n",
    "hf_zs = h5py.File('z_dataset_pre.h5', 'r')\n",
    "\n",
    "hf_mdn = h5py.File('mdn_dataset_pre.h5', 'w')\n",
    "\n",
    "counter = 0\n",
    "for i in range(len(hf_zs.keys())):\n",
    "    \n",
    "    f = hf_zs.get('z_list' + str(i))\n",
    "\n",
    "    z_i = np.array(f)\n",
    "\n",
    "    len_list = z_i.shape[0]\n",
    "\n",
    "    num_steps = int(len_list / SEQ_LEN)\n",
    "    \n",
    "    # don't keep short songs\n",
    "    if num_steps == 0: continue\n",
    "        \n",
    "    else:\n",
    "\n",
    "        #avoiding errors if the number of steps leaves no\n",
    "        #room for an extra +1 for the target\n",
    "        if len_list % SEQ_LEN == 0:\n",
    "            num_steps = num_steps - 1\n",
    "\n",
    "        idx = 0\n",
    "\n",
    "        for j in range(num_steps):\n",
    "\n",
    "            data = z_i[idx : idx + SEQ_LEN]\n",
    "            target = z_i[idx + 1 : idx + SEQ_LEN + 1]\n",
    "\n",
    "            hf_mdn.create_dataset(\"z_x_id-\" + str(counter), data=data)\n",
    "            hf_mdn.create_dataset(\"z_y_id-\" + str(counter), data=target)\n",
    "            \n",
    "            counter += 1\n",
    "\n",
    "            idx += SEQ_LEN\n",
    "            \n",
    "hf_zs.close()\n",
    "hf_mdn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sliced z's:  54415.0\n",
      "Is the first time step of y the same as the second time step of x? \n",
      " [[[ True  True  True  True  True  True  True  True  True  True  True\n",
      "    True  True  True  True  True  True  True  True  True  True  True\n",
      "    True  True  True  True  True  True  True  True  True  True  True\n",
      "    True  True  True  True  True  True  True  True  True  True  True\n",
      "    True  True  True  True  True  True  True  True  True  True  True\n",
      "    True  True  True  True  True  True  True  True  True]]]\n"
     ]
    }
   ],
   "source": [
    "hf_mdn = h5py.File('mdn_dataset_pre.h5', 'r')\n",
    "\n",
    "print(\"Number of sliced z's: \", len(list(hf_mdn.keys()))/2)\n",
    "print(\"Is the first time step of y the same as the second time step of x? \\n\" ,\\\n",
    "      list(hf_mdn.get(\"z_x_id-1\"))[1] == list(hf_mdn.get(\"z_y_id-1\"))[0])\n",
    "hf_mdn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
